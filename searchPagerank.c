#include <stdio.h>#include <stdlib.h>#include "string.h"#include "Graph.h"#include "searchPagerank.h"#include "DLList.h"/*search engine:1. given search terms - commandline arguments: main will include this2. functions:    - list findMatchedUrls("inverted.txt, query words, numSearchwords);        - read and store all the words from invertedIndex.txt into a list - limit up to 10 urls            - this list will contain all the urls        - conditions:     if only one word:            - return the list of urls    if more than one:            - we compare urls as they are being inserted - we add all the urls from one word first, then we scan through the next word and compare the urls with the urls already added - if they exist in the list, we leave it, else we remove the url from the list as it does not appear in both urls.     - findPageRank(pagerank.txt, list matchedUrlList)        - compare each of matched url list elements with pagerank.txt urls - in descending order *///assume file is open for readingDLList findUrls (FILE *f, char **searchWords, int numWords) {        //searchWords = malloc(numWords * sizeof(char*));    int maxUrls = 10;    DLList matchedUrls = newDLList();// this is what we will return    int count = 0;    int i = 0;    int k = 0;    // int  count2 = 0;    //this is used to scan in data from our txt files    //!!!normalize all words in numWords array    char * urls = malloc(maxUrls*sizeof(char *));    char * cpy = malloc(maxUrls*sizeof(char *));    int test[numWords];    DLListNode * n = matchedUrls->first;    //printf("count %d\n", count);    //if(fgetc(f) == '\n') {    //   printf("url: %s\n", &urls[k]);        //   break;    int j = 0;    int e = 0;    //test before going through code: check all search words exist       while(count < numWords) {           f = fopen("invertedIndex.txt", "r");           k = 0;        while (fscanf(f,"%s", &urls[k]) != EOF) { //read through the file till the END of file          //  printf("k testk %d %d %s\n", k, test[k], &urls[k]);            if((strcmp(searchWords[count], &urls[k]) == 0)) { //if we've found our search word                test[j] = 0;              //  printf("k testk %d %d %s\n", k, test[k], &urls[k]);                break;            }            else {            test[j] = 1;            }            k++;        }        count++;           j++;      fclose(f);       }        j = 0;    while(j < numWords) {        if(test[j] == 1) {        printf("no urls matching all search words\n");            return 0;        }        j++;    }        count = 0;                while(count < numWords) { //loop to go through each search word in the search            f = fopen("invertedIndex.txt", "r");            k = 0;                        n =matchedUrls->first; //reset match marker to 0 after each count iteration.            while(n!= NULL) {                n->i = 0;                n = n->next;            }            while (fscanf(f,"%s", &urls[k]) != EOF) { //read through the file till the END of file                                if((strcmp(searchWords[count], &urls[k]) == 0)) { //if we've found our search word                    while(DLListLength(matchedUrls) < maxUrls){//keep scaning through the urls to add in the list UNTIL we reach anothe word OR EOF.                                               fscanf(f, "%s", &urls[k]);//when we reach a new line in the txt file (new word and end of urls) - we break... also we use this condition to delete urls that don't share the same search words required                    if(!feof(f)) { //if at end of file                        strncpy(&cpy[k], &urls[k], 2);                        if(strcmp(&cpy[k], "ur") == 0) {                            if(count == 0) {                              //   printf("urladded h: %s  c%d\n", &urls[k], count);                            DLListAfter(matchedUrls, &urls[k]);                            }                        }                        else { //else if we've found all the urls for this word                          //  printf("%s copy %s url \n", &cpy[k],&urls[k]);                            if(count > 0) {                                n = matchedUrls->first;                                while(n != NULL) { //remove unmatched urls from list                                    if(n->i == 0) {                                        matchedUrls->curr = n;                                        DLListDelete(matchedUrls);                                       // printf("deleted %s\n", n->data);                                    }                                    n = n->next;                                                                    }                            }                            break;                        }                        }                        if(feof(f)) { //if at end of file                            e = 1;                            break;                        }                        if (count > 0){ //if we have more than one search word:                            n = matchedUrls->first;                            matchedUrls->curr = n;                            // printf("url: %s,  %s \n ",n->data, &urls[k]);                            // int f = 0;                            i = 0;                            while(n != NULL){  //we need to compare urls - by traversing through the urls existing. i needs to stay at 0 - we only want to go through one url[k] from the file to compare at a time per k iteration.                               // printf(")url: %s,  %s n %d count is %d i is %d\n",n->data, &urls[k], n->i, count, i);                                if(strcmp(n->data, &urls[k]) == 0) { //if we've found a matched url for both words                                    n->i = 1;                                  // printf("matched url: %s,  %s n %d count is %d i is %d\n",n->data, &urls[k], n->i, count, i);                                                                       DLListAfter(matchedUrls, &urls[k]); //if we've found a match, add to the list.                                     //printf("urladded: %s  c%d i is %d\n", &urls[k], count, i);                                     break;                                    //f++;                                    // break; //exit to look for the next matching url                                }                                n = n->next;                                i++;                                                            }                        }                                            }                                    }                                            k++;                            }                                    count++;            fclose(f);                            }       if(e == 1 && count > 1) { //if we've reached teh end of the file    // printf("here\n");    n = matchedUrls->first;    while(n != NULL) { //remove unmatched urls from list    if(n->i == 0) {    matchedUrls->curr = n;    DLListDelete(matchedUrls);    //printf("deleted %s\n", n->data);    }    n = n->next;        }    n =matchedUrls->first; //reset match marker to 0 after each count iteration.    while(n!= NULL) {    n->i = 0;    n = n->next;    }    }    // showDLList(matchedUrls);    if(DLListLength(matchedUrls) == 0) {        printf("no matching urls for ya search words m8\n");    }    return matchedUrls;}void findPagerank (FILE *f, DLList urls, FILE *stdout) {        if(DLListLength(urls) == 0) {        printf("here\n");        return;    }    char *temp = malloc(DLListLength(urls)*sizeof(char *));        char *add = malloc(1000*sizeof(char *)); //change this!!!! should be size of file or size of # of urls - check graph            DLList prUrls = newDLList();        // DLListNode * curr = prUrls->first;    // curr = prUrls->first;    int k = 0;          //int i = 0;    // f = fopen("pagerank.txt", "r");    while (fscanf(f,"%s", &temp[k]) != EOF) { //scan through pagerank.txt and store each url in the urls array        //  printf("here \n");        int len = (int)(strlen(&temp[k])-1);       // printf("curr->pr %s\n", &temp[k]);                if(k % 3 == 0) { //take in every 2nd line - take in the url names and store in list        ;            strncpy(&add[k], &temp[k],len);            //printf("temp %s %s\n", &temp[k], &add[k]);           // add[len] = '\0';                        DLListAfter(prUrls, &add[k]);         // printf("curr %s strlen, temp %s %d\n", &add[k], &temp[k], len);        }                k++;        //  i++;    }    fclose(f);    int i = 0;    k = 0;    //now we have our array of PR in descending order... we compare and match and if we find it, we write it out to stdout    DLListNode * mUrl = urls->first;    DLListNode * prUrl = prUrls->first;        while(prUrl != NULL){        mUrl = urls->first;        //printf("murl prurl %s %s\n", mUrl->data, prUrl->data);        while(mUrl!= NULL){ //traverse through all hte urls in PR list and compare with DLLISt urls                        if(strcmp(mUrl->data, prUrl->data) == 0) {                // printf("murl prurl %s %s\n", mUrl->data, prUrl->data);                fprintf(stdout, "%s\n", prUrl->data);            }            mUrl = mUrl->next;            i++;        }                prUrl = prUrl->next;                k++;    }    /*    while(mUrl != NULL){        prUrl = prUrls->first;         printf("murl prurl %s %s\n", mUrl->data, prUrl->data);        while(prUrl!= NULL){ //traverse through all hte urls in PR list and compare with DLLISt urls                        if(strcmp(mUrl->data, prUrl->data) == 0) {                // printf("murl prurl %s %s\n", mUrl->data, prUrl->data);                fprintf(stdout, "%s\n", mUrl->data);            }            prUrl = prUrl->next;            i++;        }                mUrl = mUrl->next;                        k++;    }     */}