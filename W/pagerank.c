//  pagerank.c//  Assignment 2 COMP1927//  3 June 2016//  Created by Winnie Zheng && Vivian Bakiris#include <stdio.h>#include <stdlib.h>#include <string.h>#include "graph.h"#include "math.h"#include "pagerank.h"#include "searchPagerank.h"#include "prlist.h"#include <sys/stat.h>#include <errno.h>#include <unistd.h>#include <assert.h>#include <ctype.h>// reads in collection.txt and returns a list of URLS. This function will read the urls from collection.txt (by calling getList from List.c) and store the URLS in list lDLListPR getCollection() {     FILE *f = fopen("collection.txt", "r");    DLListPR l = newDLListPR();    l =  getDLListPR(f);    return l;    }   //return the num of urls in collectionint numUrls() {    DLListPR l = getCollection();    int num = DLListPRLength(l);    return num;}//create a graph to store our collection.txt dataGraph getGraph(){    //creates a new graph by calling Graphnew in graph.h - adds in nV from listLength function    DLListPR l = getCollection();        DLListPR k = listcopyPR(l);    DLListPR m = listcopyPR(l);          int nV = numUrls();    Graph g = newGraph(nV, k);     int i = 0;    char * txt = ".txt";    int x = 0;    while(l->first != NULL) {        strcat(l->first->data, txt); //iterate through ALL url files        char * url = malloc(fsize(l->first->data));        FILE *f = 0;        if(access(l->first->data, F_OK ) != -1 ) { //check for file existence before opening file            f = fopen(l->first->data, "r");            x = 0;            while((fscanf(f, "%s", &url[x])) != EOF) {                if((strcmp(&url[x],"#start")!=0) && (strcmp(&url[x],"Section-1") !=0)){ //extract "url" text lines from txt files and treat as connected vertices                    addEdge(g, m->first->data, &url[x]); //add an edge if we find connected components                                    }                             x++;                        }            l->first = l->first->next; //move on to the next url txt file            m->first = m->first->next;            i++;            fclose(f);        }        else {            l->first = l->first->next; //move on to the next url txt file            m->first = m->first->next;        }    }        return g;}//calculate our page rank for each urlvoid PageRank(double d, double diffPR, int maxIter) {      Graph g = getGraph();    int nV = numUrls();    //showGraph(g, 1); //display graph in matrix form    int counter;    double PR[nV];    double PROld[nV];    for(counter = 0; counter < nV; counter++) { //set initial/default PR for all the urls        PR[counter] = (1.0/nV);    }    int iterCounter = 0;    double diff = diffPR;         int urlCurr;    int urlConn = 0;    double sum = 0;    int outDegreeV[nV];    int n = 0;        //set 0's for default values    while(n < nV) {        outDegreeV[n] = 0;        n++;    }    n = 0;    FILE *pr = fopen("pagerankList.txt", "w");    int outDegreeC = 1;    //default value of 1 outdeegree vertex (divide by 1)    int k = 0;    while(n < nV) {        k = 0;        while(k < nV) {        if(isConnected(g, n, k) == 1) {            outDegreeV[n] += outDegreeC;                    }            k++;                   }         n++;    }    //the loop that controls all loops inside -> when it stops, we will have finished iterating.    while (iterCounter < maxIter && (diff  >= diffPR)) {        diff = 0;        urlCurr = 0;        //iterate through all urls until we find one that points to our current URL.        for(urlCurr = 0; urlCurr < nV; urlCurr++) {                  PROld[urlCurr] = PR[urlCurr];            sum = 0; // reset the sum after iteration            urlConn = 0;                        while(urlConn < nV) {                if((isConnected(g, urlCurr, urlCurr) == 1)){ //self loops - exit loop                     break;                }                //if we have a connection between two vericies(ignoring self loops/parallel edges) calculate the sum                if(isConnected(g, urlConn, urlCurr) == 1){                    if(outDegreeV[urlConn] == 0) {                         sum = (sum + ((PR[urlConn])/1.0)); //if our vertices/urls don't have outdegree verticies.. default to 1 for calculation                    }                    else {                       sum = (sum + ((PR[urlConn])/(outDegreeV[urlConn])));                    }                }                urlConn++;            }                      PR[urlCurr] = (1-d)/nV + d * sum; //calculate PR for each iteration            diff = diff + fabs(PROld[urlCurr] - PR[urlCurr]); //calculate diff        }          iterCounter++;    }        //write to pagerankList    int u = 0;    while(u < nV) {    fprintf(pr, "%s%s %d%s %.7f \n",IDtoVertex(g,u),",",outDegreeV[u],",",PR[u]);        u++;    }   fclose(pr);        //sort file in descending order    DLListPR pagerankList = newDLListPR();    FILE *prn = fopen("pagerankList.txt", "r");    pagerankList = PageRankAppend(prn, pagerankList);    printListPR(pagerankList);    fclose(prn);    freeDLListPR(pagerankList);}